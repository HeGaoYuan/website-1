var suggestions=document.getElementById('suggestions'),userinput=document.getElementById('userinput');document.addEventListener('keydown',inputFocus);function inputFocus(a){a.keyCode===191&&(a.preventDefault(),userinput.focus()),a.keyCode===27&&(userinput.blur(),suggestions.classList.add('d-none'))}document.addEventListener('click',function(a){var b=suggestions.contains(a.target);b||suggestions.classList.add('d-none')}),document.addEventListener('keydown',suggestionFocus);function suggestionFocus(b){const d=suggestions.querySelectorAll('a'),e=[...d],a=e.indexOf(document.activeElement);let c=0;b.keyCode===38?(b.preventDefault(),c=a>0?a-1:0,d[c].focus()):b.keyCode===40&&(b.preventDefault(),c=a+1<e.length?a+1:a,d[c].focus())}(function(){var b=new FlexSearch({preset:'score',cache:!0,doc:{id:'id',field:['title','description','content'],store:['href','title','description']}}),c=[{id:0,href:"https://kubedl.io/docs/workloads/pytorch/",title:"PyTorch",description:"",content:""},{id:1,href:"https://kubedl.io/docs/prologue/introduction/",title:"Introduction",description:"KubeDL runs your deep learning workloads on Kubernetes.",content:'\u003cp\u003eCurrently, KubeDL supports running \u003ca href="https://github.com/tensorflow/tensorflow"\u003eTensorFlow\u003c/a\u003e, \u003ca href="https://github.com/pytorch/pytorch"\u003ePyTorch\u003c/a\u003e,\n\u003ca href="https://github.com/dmlc/xgboost"\u003eXGBoost\u003c/a\u003e, \u003ca href="https://github.com/mars-project/mars"\u003eMars\u003c/a\u003e and MPI distributed training jobs on Kubernetes.\u003c/p\u003e\n\u003ch2 id="key-features"\u003eKey Features\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eSupport different kinds of deep learning training jobs in a single controller. You don\u0026rsquo;t need to run each controller for each job kind.\u003c/li\u003e\n\u003cli\u003eExpose unified \u003ca href="https://kubedl.io/docs/references/metrics/"\u003eprometheus metrics\u003c/a\u003e for job stats.\u003c/li\u003e\n\u003cli\u003eSave job metadata in a pluggable storage backend such as Mysql to outlive api-server state.\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://kubedl.io/docs/recipes/code-sync/"\u003eSync files\u003c/a\u003e on container launch. You no longer need to rebuild the image to include the custom code every time.\u003c/li\u003e\n\u003cli\u003eRun jobs with host network.\u003c/li\u003e\n\u003cli\u003eSupport advanced scheduling features such as gang scheduling.\u003c/li\u003e\n\u003cli\u003e[Work-in-progress] a catchy \u003ca href="#job-dashboard"\u003edashboard\u003c/a\u003e !\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id="get-started"\u003eGet started\u003c/h2\u003e\n\u003cp\u003eThere are two main ways to install KubeDL.\u003c/p\u003e\n\u003ch3 id="install-using-helm"\u003eInstall using Helm\u003c/h3\u003e\n\u003cp\u003eInstall KubeDL using Helm charts. \u003ca href="https://kubedl.io/docs/prologue/install-using-helm/"\u003eGo →\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="install-using-yaml-files"\u003eInstall using YAML files\u003c/h3\u003e\n\u003cp\u003eInstall KubeDL using YAML files. \u003ca href="https://kubedl.io/docs/prologue/quick-start/"\u003eGo →\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id="recipes"\u003eRecipes\u003c/h2\u003e\n\u003cp\u003eGet instructions on how to accomplish common tasks with KubeDL. \u003ca href="https://getdoks.org/docs/recipes/project-configuration/"\u003eRecipes →\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id="reference"\u003eReference\u003c/h2\u003e\n\u003cp\u003eReferences for apis, metrics etc. \u003ca href="https://kubedl.io/docs/references/"\u003eReference →\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id="contributing"\u003eContributing\u003c/h2\u003e\n\u003cp\u003eFind out how to contribute to KubeDL. \u003ca href="https://kubedl.io/docs/contributing/how-to-contribute/"\u003eContributing →\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id="help"\u003eHelp\u003c/h2\u003e\n\u003cp\u003eGet help on KubeDL. \u003ca href="https://kubedl.io/docs/help/"\u003eHelp →\u003c/a\u003e\u003c/p\u003e\n'},{id:2,href:"https://kubedl.io/docs/prologue/",title:"Prologue",description:"Prologue KubeDL.",content:""},{id:3,href:"https://kubedl.io/docs/references/metrics/",title:"Metrics",description:"",content:"\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eMetric Names\u003c/th\u003e\n\u003cth\u003elabel\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_created\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs created\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_deleted\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs deleted\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_successful\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs successfully finished\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_failed\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs failed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_restarted\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs restarted\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_running\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs currently running\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_pending\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs currently pending\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_first_pod_launch_delay_seconds\u003c/td\u003e\n\u003ctd\u003ekind, name, namespace, uid\u003c/td\u003e\n\u003ctd\u003eHistogram for recording launch delay duration (from job created to first pod running)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_all_pods_launch_delay_seconds\u003c/td\u003e\n\u003ctd\u003ekind, name, namespace, uid\u003c/td\u003e\n\u003ctd\u003eHistogram for recording launch delay duration (from job created to all pods running)\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003ccode\u003elabel\u003c/code\u003e specifics the labels supported for the corresponding prometheus metrics\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ekind\u003c/code\u003e - the target job kind, e.g. TFJob, PyTorchJob, MarsJob, XGBoostJob\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ename\u003c/code\u003e - the name of the job\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003enamespace\u003c/code\u003e - the namespace of the job\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003euid\u003c/code\u003e - the uid of the job\u003c/li\u003e\n\u003c/ul\u003e\n"},{id:4,href:"https://kubedl.io/docs/recipes/code-sync/",title:"File Sync",description:"Sync files on container launch.",content:'\u003cp\u003eKubeDL supports syncing files from remote on container launch.\nUser can modify the code, reference the code repository and run the jobs without re-building the image every time to include the modified code.\u003c/p\u003e\n\u003cp\u003eCurrently, only support downloading from github. The implementation is pluggable and can easily support other distributed filesystem like HDFS.\u003c/p\u003e\n\u003ch3 id="git-hub"\u003eGit Hub\u003c/h3\u003e\n\u003cp\u003eUsers can set the git config in the job\u0026rsquo;s annotation with key \u003ccode\u003ekubedl.io/git-sync-config\u003c/code\u003e as below. The git repo will be\ndownloaded and saved in the container\u0026rsquo;s \u003ccode\u003eworking dir\u003c/code\u003e by default. Please use the git repo\u0026rsquo;s clone url ending with the \u003ccode\u003e.git\u003c/code\u003e,\nrather than the git repo\u0026rsquo;s web url.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003e    apiVersion: \u0026quot;kubeflow.org/v1\u0026quot;\n    kind: \u0026quot;TFJob\u0026quot;\n    metadata:\n      name: \u0026quot;mnist\u0026quot;\n      namespace: kubedl\n      annotations:\n +      kubedl.io/git-sync-config: \'{\u0026quot;source\u0026quot;: \u0026quot;https://github.com/alibaba/kubedl.git\u0026quot; }\'\n    spec:\n      cleanPodPolicy: None\n      tfReplicaSpecs:\n        ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eA full list of supported options are:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-json5"\u003e\u0026quot;source\u0026quot;: \u0026quot;https://github.com/sample/sample.git\u0026quot;,  // code source (required).\n\u0026quot;image\u0026quot;: \u0026quot;xxx\u0026quot;,     // the image to execute the git-sync logic (optional).\n\u0026quot;rootPath\u0026quot;: \u0026quot;xxx\u0026quot;,  // the path to save downloaded files (optional).\n\u0026quot;destPath\u0026quot;: \u0026quot;xxx\u0026quot;,  // the name of (a symlink to) a directory in which to check-out files (optional).\n\u0026quot;envs\u0026quot;: [],         // user-customized environment variables (optional).\n\u0026quot;branch\u0026quot;: \u0026quot;xxx\u0026quot;,    // git repo branch (optional).\n\u0026quot;revison\u0026quot;: \u0026quot;xxx\u0026quot;,   // git repo commit revision (optional).\n\u0026quot;depth\u0026quot;: \u0026quot;xxx\u0026quot;,     // git sync depth (optional).\n\u0026quot;maxFailures\u0026quot; : 3,  // max consecutive failures allowed (optional).\n\u0026quot;ssh\u0026quot;: false,       // use ssh mode or not (optional).\n\u0026quot;sshFile\u0026quot;: \u0026quot;xxx\u0026quot;,   // ssh file path (optional).\n\u0026quot;user\u0026quot;: \u0026quot;xxx\u0026quot;,      // git config username (optional).\n\u0026quot;password\u0026quot;: \u0026quot;xxx\u0026quot;   // git config password (optional).\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:5,href:"https://kubedl.io/docs/recipes/hostnetwork/",title:"Host Network",description:"Run jobs with host network",content:""},{id:6,href:"https://kubedl.io/docs/workloads/tensorflow/",title:"TensorFlow",description:"",content:""},{id:7,href:"https://kubedl.io/docs/references/flags/",title:"Startup flags",description:"KubeDL startup flags",content:"\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eFlag Name\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003cth\u003eDefault\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003econtroller-metrics-addr\u003c/td\u003e\n\u003ctd\u003eThe prometheus metrics endpoint for job stats\u003c/td\u003e\n\u003ctd\u003e8088\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003eenable-leader-election\u003c/td\u003e\n\u003ctd\u003eEnable leader election for controller manager. Enabling this will ensure there is only one active controller manager.\u003c/td\u003e\n\u003ctd\u003efalse\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003egang-scheduler-name\u003c/td\u003e\n\u003ctd\u003eThe name of gang scheduler, by default it is set to empty meaning not enalbing gang scheduling\u003c/td\u003e\n\u003ctd\u003e\u0026quot;\u0026quot;\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003emax-reconciles\u003c/td\u003e\n\u003ctd\u003eThe number of max concurrent reconciles of each controller\u003c/td\u003e\n\u003ctd\u003e1\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n"},{id:8,href:"https://kubedl.io/docs/contributing/how-to-contribute/",title:"How to Contribute",description:"You are very welcome to contribute to KubeDL",content:'\u003cp\u003eKubeDL is written in the form of Kubernetes operator and use \u003ca href="https://github.com/kubernetes-sigs/kubebuilder"\u003eKubeBuilder\u003c/a\u003e for code scaffolding.\u003c/p\u003e\n\u003ch3 id="build-the-binary"\u003eBuild the binary\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="make manager"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003emake manager\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="run-the-tests"\u003eRun the tests\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="make test"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003emake test\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="generate-manifests-crd-rbac-yaml-files-etc"\u003eGenerate manifests: CRD, RBAC YAML files etc\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="make manifests"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003emake manifests\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="build-the-docker-image"\u003eBuild the docker image\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="export IMG= \u0026\u0026 make docker-build"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003eexport IMG=\u0026lt;your_image_name\u0026gt; \u0026amp;\u0026amp; make docker-build\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="push-the-image"\u003ePush the image\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="docker push "\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003edocker push \u0026lt;your_image_name\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCheck the \u003ccode\u003eMakefile\u003c/code\u003e under github root directory for more details\u003c/p\u003e\n\u003cp\u003eTo develop/debug KubeDL controller manager, please check the \u003ca href="https://kubedl.io/docs/contributing/develop-guide/"\u003edebug guide\u003c/a\u003e.\u003c/p\u003e\n'},{id:9,href:"https://kubedl.io/docs/prologue/install-using-helm/",title:"Install Using Helm",description:"Install KubeDL using Helm",content:'\u003ch2 id="install-helm"\u003eInstall Helm\u003c/h2\u003e\n\u003cp\u003eHelm is a package manager for Kubernetes. You can install helm with command below on MacOS\u003c/p\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="brew install helm"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ebrew install helm\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCheck the \u003ca href="https://helm.sh/docs/intro/install/"\u003ehelm website\u003c/a\u003e for more details.\u003c/p\u003e\n\u003ch2 id="install-kubedl"\u003eInstall KubeDL\u003c/h2\u003e\n\u003cp\u003eFrom the root directory, run\u003c/p\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="helm install kubedl ./helm/kubedl"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ehelm install kubedl ./helm/kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can override default values defined in \u003ccode\u003e./helm/kubedl/values.yaml\u003c/code\u003e with \u003ccode\u003e--set\u003c/code\u003e flag, for example:\u003c/p\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="helm install kubedl ./helm/kubedl --set kubedlSysNamespace=kube-system --set resources.requests.cpu=1024m --set resources.requests.memory=2Gi"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ehelm install kubedl ./helm/kubedl --set kubedlSysNamespace=kube-system --set resources.requests.cpu=1024m --set resources.requests.memory=2Gi\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHelm will render templates and apply them to cluster and you are good to go :)\u003c/p\u003e\n\u003ch2 id="enable-specific-job-kind"\u003eEnable specific job Kind\u003c/h2\u003e\n\u003cp\u003eKubeDL supports all kinds of jobs(tensorflow, pytorch etc.) in a single Kubernetes operator. You can selectively enable the kind of jobs to support.\nThere are three options:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDefault option. Just install the job CRDs required. KubeDL will automatically enable the corresponding job controller.\u003c/li\u003e\n\u003cli\u003eSet env \u003ccode\u003eWORKLOADS_ENABLE\u003c/code\u003e in KubeDL container. The value is a list of job types to be enabled. For example, \u003ccode\u003eWORKLOADS_ENABLE=TFJob,PytorchJob\u003c/code\u003e means only Tensorflow and Pytorch Job are enabled.\u003c/li\u003e\n\u003cli\u003eSet startup flags \u003ccode\u003e--workloads\u003c/code\u003e in KubeDL container command args. The value is a list of job types to be enabled like \u003ccode\u003e--workloads TFJob,PytorchJob\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n'},{id:10,href:"https://kubedl.io/docs/workloads/",title:"Workloads",description:"Workloads",content:""},{id:11,href:"https://kubedl.io/docs/contributing/develop-guide/",title:"How to Develop",description:"How to develop KubeDL",content:'\u003ch2 id="run-kubedl-in-cluster"\u003eRun KubeDL in Cluster\u003c/h2\u003e\n\u003ch3 id="install-docker"\u003eInstall docker\u003c/h3\u003e\n\u003cp\u003eFollow the \u003ca href="https://docs.docker.com/install/"\u003eofficial docker installation guide\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id="install-minikube"\u003eInstall minikube\u003c/h3\u003e\n\u003cp\u003eFollow the \u003ca href="https://kubernetes.io/docs/tasks/tools/install-minikube/"\u003eofficial minikube installation guide\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id="customize-kubedl-code"\u003eCustomize KubeDL code\u003c/h3\u003e\n\u003cp\u003eMake your own code changes and validate the build by running \u003ccode\u003emake manager\u003c/code\u003e in KubeDL directory.\u003c/p\u003e\n\u003ch3 id="deploy-customized-operator"\u003eDeploy customized operator\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ePrerequisites: create a \u003ca href="https://hub.docker.com/"\u003edock hub\u003c/a\u003e account ($DOCKERID), and create a \u003ccode\u003ekubedl\u003c/code\u003e repository. Also,\n\u003ca href="https://kubedl.io/docs/prologue/introduction/"\u003einstall KubeDL\u003c/a\u003e;\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 1: \u003ccode\u003edocker login\u003c/code\u003e with the $DOCKERID account;\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 2: \u003ccode\u003eexport IMG=\u0026lt;image_name\u0026gt;\u003c/code\u003e to specify the target image name. e.g., \u003ccode\u003eexport IMG=$DOCKERID/kubedl:test\u003c/code\u003e;\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 3: \u003ccode\u003emake docker-build\u003c/code\u003e to build the image locally;\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 4: \u003ccode\u003emake docker-push\u003c/code\u003e to push the image to dock hub under the \u003ccode\u003ekubedl\u003c/code\u003e repository;\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 5: change the \u003ccode\u003econfig/manager/all_in_one.yaml\u003c/code\u003e and replace the image of the kubedl deployment to \u003ccode\u003e$DOCKERID/kubedl:test\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003espec:\n      containers:\n        - command:\n            - /manager\n          image: $DOCKERID/kubedl:test\n          imagePullPolicy: Always\n          name: kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 6: \u003ccode\u003ekubectl delete deployment kubedl-controller-manager -n kubedl-system\u003c/code\u003e to remove the old deployment if any;\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 7: \u003ccode\u003ekubectl apply -f config/manager/all_in_one.yaml\u003c/code\u003e to install the new deployment with the customized operator image;\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can now perform manual tests and use \u003ccode\u003ekubectl logs kubedl-controller-manager-0 -n kubedl-system\u003c/code\u003e to check controller logs for debugging.\u003c/p\u003e\n\u003ch2 id="run-kubedl-locally"\u003eRun KubeDL locally\u003c/h2\u003e\n\u003ch3 id="set-up-credentials"\u003eSet up credentials\u003c/h3\u003e\n\u003cp\u003eTo run KubeDL locally, you must have the access to the kubernetes cluster, the credential is the\nkube-config cert file.\u003c/p\u003e\n\u003ch3 id="install-crds-and-run-kubedl-operator-locally"\u003eInstall CRDs and run KubeDL operator locally\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003eexport KUBECONFIG=${PATH_TO_CONFIG}\n// or specify the path by --kubeconfig {PATH_TO_CONFIG}\nmake install\nmake run\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eKubeDL supports running workloads selectively. You can enable a specific workload by parsing the\nparameter \u003ccode\u003e--workloads {workload-to-debug}\u003c/code\u003e while starting KubeDL. Check the printed logs to see\nif the job controller is started as expected.\u003c/p\u003e\n'},{id:12,href:"https://kubedl.io/docs/recipes/persistency/",title:"Metadata/Events Persistency",description:"",content:""},{id:13,href:"https://kubedl.io/docs/contributing/code-of-conduct/",title:"Code of Conduct",description:"code of conduct",content:'\u003ch2 id="our-pledge"\u003eOur Pledge\u003c/h2\u003e\n\u003cp\u003eWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion, or sexual identity\nand orientation.\u003c/p\u003e\n\u003cp\u003eWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\u003c/p\u003e\n\u003ch2 id="our-standards"\u003eOur Standards\u003c/h2\u003e\n\u003cp\u003eExamples of behavior that contributes to a positive environment for our\ncommunity include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDemonstrating empathy and kindness toward other people\u003c/li\u003e\n\u003cli\u003eBeing respectful of differing opinions, viewpoints, and experiences\u003c/li\u003e\n\u003cli\u003eGiving and gracefully accepting constructive feedback\u003c/li\u003e\n\u003cli\u003eAccepting responsibility and apologizing to those affected by our mistakes,\nand learning from the experience\u003c/li\u003e\n\u003cli\u003eFocusing on what is best not just for us as individuals, but for the\noverall community\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eExamples of unacceptable behavior include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe use of sexualized language or imagery, and sexual attention or\nadvances of any kind\u003c/li\u003e\n\u003cli\u003eTrolling, insulting or derogatory comments, and personal or political attacks\u003c/li\u003e\n\u003cli\u003ePublic or private harassment\u003c/li\u003e\n\u003cli\u003ePublishing others\' private information, such as a physical or email\naddress, without their explicit permission\u003c/li\u003e\n\u003cli\u003eOther conduct which could reasonably be considered inappropriate in a\nprofessional setting\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id="enforcement-responsibilities"\u003eEnforcement Responsibilities\u003c/h2\u003e\n\u003cp\u003eCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\u003c/p\u003e\n\u003cp\u003eCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\u003c/p\u003e\n\u003ch2 id="scope"\u003eScope\u003c/h2\u003e\n\u003cp\u003eThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\u003c/p\u003e\n\u003ch2 id="enforcement"\u003eEnforcement\u003c/h2\u003e\n\u003cp\u003eInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\n.\nAll complaints will be reviewed and investigated promptly and fairly.\u003c/p\u003e\n\u003cp\u003eAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\u003c/p\u003e\n\u003ch2 id="enforcement-guidelines"\u003eEnforcement Guidelines\u003c/h2\u003e\n\u003cp\u003eCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\u003c/p\u003e\n\u003ch3 id="1-correction"\u003e1. Correction\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eCommunity Impact\u003c/strong\u003e: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eConsequence\u003c/strong\u003e: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\u003c/p\u003e\n\u003ch3 id="2-warning"\u003e2. Warning\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eCommunity Impact\u003c/strong\u003e: A violation through a single incident or series\nof actions.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eConsequence\u003c/strong\u003e: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or\npermanent ban.\u003c/p\u003e\n\u003ch3 id="3-temporary-ban"\u003e3. Temporary Ban\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eCommunity Impact\u003c/strong\u003e: A serious violation of community standards, including\nsustained inappropriate behavior.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eConsequence\u003c/strong\u003e: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\u003c/p\u003e\n\u003ch3 id="4-permanent-ban"\u003e4. Permanent Ban\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eCommunity Impact\u003c/strong\u003e: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior,  harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eConsequence\u003c/strong\u003e: A permanent ban from any sort of public interaction within\nthe community.\u003c/p\u003e\n\u003ch2 id="attribution"\u003eAttribution\u003c/h2\u003e\n\u003cp\u003eThis Code of Conduct is adapted from the \u003ca href="https://www.contributor-covenant.org"\u003eContributor Covenant\u003c/a\u003e,\nversion 2.0, available at\nhttps://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\u003c/p\u003e\n\u003cp\u003eCommunity Impact Guidelines were inspired by \u003ca href="https://github.com/mozilla/diversity"\u003eMozilla\u0026rsquo;s code of conduct\nenforcement ladder\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eFor answers to common questions about this code of conduct, see the FAQ at\nhttps://www.contributor-covenant.org/faq. Translations are available at\nhttps://www.contributor-covenant.org/translations.\u003c/p\u003e\n'},{id:14,href:"https://kubedl.io/docs/prologue/install-using-yaml/",title:"Install Using Yaml",description:"",content:'\u003ch2 id="install-crds"\u003eInstall CRDs\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/crd/bases/kubeflow.org_pytorchjobs.yaml\nkubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/crd/bases/kubeflow.org_tfjobs.yaml\nkubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/crd/bases/xgboostjob.kubeflow.org_xgboostjobs.yaml\nkubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/crd/bases/kubedl.io_marsjobs.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="install-kubedl-operator"\u003eInstall KubeDL operator\u003c/h2\u003e\n\u003cp\u003eA single yaml file including everything: deployment, rbac etc.\u003c/p\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="kubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/manager/all_in_one.yaml"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/manager/all_in_one.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe official KubeDL operator image is hosted under \u003ca href="https://hub.docker.com/r/kubedl/kubedl"\u003edocker hub\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id="enable-specific-job-kind"\u003eEnable specific job Kind\u003c/h2\u003e\n\u003cp\u003eKubeDL supports all kinds of jobs(tensorflow, pytorch etc.) in a single Kubernetes operator. You can selectively enable the kind of jobs to support.\nThere are three options:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDefault option. Just install the job CRDs required. KubeDL will automatically enable the corresponding job controller.\u003c/li\u003e\n\u003cli\u003eSet env \u003ccode\u003eWORKLOADS_ENABLE\u003c/code\u003e in KubeDL container. The value is a list of job types to be enabled. For example, \u003ccode\u003eWORKLOADS_ENABLE=TFJob,PytorchJob\u003c/code\u003e means only Tensorflow and Pytorch Job are enabled.\u003c/li\u003e\n\u003cli\u003eSet startup flags \u003ccode\u003e--workloads\u003c/code\u003e in KubeDL container command args. The value is a list of job types to be enabled like \u003ccode\u003e--workloads TFJob,PytorchJob\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n'},{id:15,href:"https://kubedl.io/docs/workloads/mars/",title:"Mars",description:"Running mars on Kubernetes",content:'\u003ch2 id="whats-mars"\u003eWhat\u0026rsquo;s Mars\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eMars\u003c/code\u003e is a tensor-based unified framework for large-scale data computation which scales Numpy, Pandas and Scikit-learn,\nsee \u003ca href="https://github.com/mars-project/mars"\u003emars-repo\u003c/a\u003e for details. As a data computation framework, \u003ccode\u003emars\u003c/code\u003e is easy to\nscale out and can run across hundreds of machines simultaneously to accelerate large scale data tasks.\u003cbr\u003e\u003c/p\u003e\n\u003cp\u003eA distributed mars job includes 3 roles to collaborate with each other：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eWebService\u003c/strong\u003e: web-service accepts requests from end-users and forwards the whole tensor-graph to scheduler, it provides a dashboard for end users to track job status and submit tasks interactively.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eScheduler\u003c/strong\u003e: scheduler compiles and holds a global view of tensor-graph, it schedules \u0026lsquo;operands\u0026rsquo; and \u0026lsquo;chunks\u0026rsquo; to workers.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWorker\u003c/strong\u003e:  worker listen to \u0026lsquo;operands\u0026rsquo; and \u0026lsquo;chunks\u0026rsquo; dispatched by scheduler, executes the tasks, and reports results back to scheduler.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id="run-mars-with-kubedl"\u003eRun Mars with KubeDL\u003c/h2\u003e\n\u003cp\u003eRun \u003ccode\u003emars\u003c/code\u003e job on kubernetes natively.\u003c/p\u003e\n\u003ch3 id="1-deploy-kubedl"\u003e1. Deploy KubeDL\u003c/h3\u003e\n\u003cp\u003eFollow the \u003ca href="https://kubedl.io/docs/prologue/introduction/"\u003einstallation tutorial\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id="2-apply-mars-crd"\u003e2. Apply Mars CRD\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eMars\u003c/code\u003e CRD(CustomResourceDefinition) manifest file describes the structure of a mars job spec. Run the following to apply the CRD:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/crd/bases/kubedl.io_marsjobs.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="3-create-a-mars-job"\u003e3. Create a Mars Job\u003c/h3\u003e\n\u003cp\u003eCreate a YAML spec that describes the requirements of a MarsJob such as the worker, scheduler, WebService like below\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: kubedl.io/v1alpha1\nkind: MarsJob\nmetadata:\n  name: mars-test-demo\n  namespace: default\nspec:\n  cleanPodPolicy: None\n  webHost: mars.domain.com\n  marsReplicaSpecs:\n    Scheduler:\n      replicas: 1\n      restartPolicy: Never\n      template:\n        metadata:\n          labels:\n            mars/service-type: marsscheduler\n        spec:\n          containers:\n            - command:\n                - /bin/sh\n                - -c\n                - python -m mars.deploy.kubernetes.scheduler\n              image: mars-image\n              imagePullPolicy: Always\n              name: mars\n              resources:\n                limits:\n                  cpu: 2\n                  memory: 2Gi\n                requests:\n                  cpu: 2\n                  memory: 2Gi\n          serviceAccountName: kubedl-sa\n    WebService:\n      replicas: 1\n      restartPolicy: Never\n      template:\n        metadata:\n          labels:\n            mars/service-type: marswebservice\n        spec:\n          containers:\n            - command:\n                - /bin/sh\n                - -c\n                - python -m mars.deploy.kubernetes.web\n              image: mars-image\n              imagePullPolicy: Always\n              name: mars\n              resources:\n                limits:\n                  cpu: 2\n                  memory: 2Gi\n                requests:\n                  cpu: 2\n                  memory: 2Gi\n          serviceAccountName: kubedl-sa\n    Worker:\n      replicas: 2\n      restartPolicy: Never\n      template:\n        metadata:\n          labels:\n            mars/service-type: marsworker\n        spec:\n          containers:\n            - command:\n                - /bin/sh\n                - -c\n                - python -m mars.deploy.kubernetes.worker\n              image: mars-image\n              imagePullPolicy: Always\n              name: mars\n              resources:\n                limits:\n                  cpu: 2\n                  memory: 2Gi\n                requests:\n                  cpu: 2\n                  memory: 2Gi\n          serviceAccountName: kubedl-sa\nstatus: {}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003espec\u003c/code\u003e field describes the requirement of each replica, including \u003ccode\u003ereplicas\u003c/code\u003e, \u003ccode\u003erestartPolicy\u003c/code\u003e, \u003ccode\u003etemplate\u003c/code\u003e\u0026hellip;and\nthe \u003ccode\u003estatus\u003c/code\u003e field describes the job current status. Run following command to start an example mars job:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl create -f example/mars/mars-test-demo.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCheck the mars job status:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003e$ kubectl get marsjob\nNAME             STATE     AGE   FINISHED-TTL   MAX-LIFETIME\nmars-test-demo   Running   40m\n$ kubectl get pods\nNAME                                            READY   STATUS             RESTARTS   AGE\nmars-test-demo-scheduler-0                      1/1     Running            0          40m\nmars-test-demo-webservice-0                     1/1     Running            0          40m\nmars-test-demo-worker-0                         1/1     Running            0          40m\nmars-test-demo-worker-1                         1/1     Running            0          40m\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="4-access-web-service"\u003e4. Access web-service.\u003c/h3\u003e\n\u003cfigure\u003e\n  \u003cimg class="img-fluid lazyload blur-up" data-sizes="auto" src="https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_20x0_resize_box_2.png" data-srcset="https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_900x0_resize_box_2.png 900w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_800x0_resize_box_2.png 800w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_700x0_resize_box_2.png 700w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_600x0_resize_box_2.png 600w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_500x0_resize_box_2.png 500w" width="892" height="452" alt="mars-ingress"\u003e\n  \u003cnoscript\u003e\u003cimg class="img-fluid" sizes="100vw" srcset="https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_900x0_resize_box_2.png 900w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_800x0_resize_box_2.png 800w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_700x0_resize_box_2.png 700w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_600x0_resize_box_2.png 600w,https://kubedl.io/docs/workloads/mars/mars-ingress_hu3d024fe99bd4d562ba755cd6f9fa87db_47305_500x0_resize_box_2.png 500w" src="https://kubedl.io/docs/workloads/mars/mars-ingress.png" width="892" height="452" alt="mars-ingress"\u003e\u003c/noscript\u003e\n  \u003cfigcaption class="figure-caption"\u003emars-ingress\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eWeb service visualizes job status, computation process progress and provides an entry for interactive submission.\nHowever, web service instance was running as a pod inside a kubernetes cluster which may not be accessible by external users.\n\u003ccode\u003eKubeDL\u003c/code\u003e provides two access modes for users in different network environment.\u003c/p\u003e\n\u003ch4 id="41-access-web-service-in-cluster"\u003e4.1 Access web-service in-cluster.\u003c/h4\u003e\n\u003cp\u003eFor users in the same network environment with web service instance, they can directly access its \u003cem\u003eservice\u003c/em\u003e without any other additional configurations,\nand the address is formatted as: \u003ccode\u003e{webservice-name}.{namespace}\u003c/code\u003e, it is a \u003ccode\u003eA\u003c/code\u003e record generated by \u003ccode\u003eCoreDNS\u003c/code\u003e, so you have to ensure that \u003ccode\u003eCoreDNS\u003c/code\u003e has been\ndeployed.\u003c/p\u003e\n\u003ch4 id="42-access-web-service-outside-cluster"\u003e4.2 Access web-service outside cluster.\u003c/h4\u003e\n\u003cp\u003eFor users in different network environment(e.g. an internet user wants to access a mars web-service running in vpc),\nusers have to apply an SLB address first, so that they can ping the ip in \u003cstrong\u003evpc\u003c/strong\u003e with a public address by SLB domain resolving, then in job spec, users just need fill the \u003ccode\u003espec.webHost\u003c/code\u003e field with\ntheir applied SLB address, \u003ccode\u003eKubeDL\u003c/code\u003ewill generated ingress instance with routing rules, so that external traffic can be routed to target web service and that\nbecomes available for outside users.\u003c/p\u003e\n\u003ch3 id="5-memory-tuning-policy"\u003e5. Memory Tuning Policy\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eWorker\u003c/code\u003e is the role that actually performs computing tasks in \u003ccode\u003eMarsJob\u003c/code\u003e.\nMars supports running jobs in different memory usage scenarios. For example, swap cold in-memory data out to spill dirs and persist in kubernetes ephemeral-storage.\n\u003ccode\u003eMars\u003c/code\u003e provides plentiful memory tuning options which has been integrated to \u003ccode\u003eMarsJob\u003c/code\u003e type definition, including :\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eplasmaStore: PlasmaStore specify the socket path of plasma store that handles shared memory between all worker processes.\u003c/li\u003e\n\u003cli\u003elockFreeFileIO: LockFreeFileIO indicates whether spill dirs are dedicated or not.\u003c/li\u003e\n\u003cli\u003espillDirs: SpillDirs specify multiple directory paths, when size of in-memory objects is about to reach the limitation, mars workers will swap cold data out to spill dirs and persist in ephemeral-storage.\u003c/li\u003e\n\u003cli\u003eworkerCachePercentage: WorkerCachePercentage specify the percentage of total available memory size can be used as cache, it will be overridden by workerCacheSize if it is been set.\u003c/li\u003e\n\u003cli\u003eworkerCacheSize：WorkerCacheSize specify the exact cache quantity can be used.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eusers can set above options in \u003ccode\u003ejob.spec.memoryTuningPolicy\u003c/code\u003e field:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: kubedl.io/v1alpha1\nkind: MarsJob\nmetadata:\n  name: mars-test-demo\n  namespace: default\nspec:\n  cleanPodPolicy: None\n  memoryTuningPolicy:\n    plasmaStore: string              # /etc/pstore/...\n    lockFreeFileIO: bool             # false\n    spillDirs: []string              # ...\n    workerCachePercentage: int32     # 80, indicates 80%\n    workerCacheSize: quantity        # 10Gi\n  marsReplicaSpecs:\n    ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="run-mars-in-standalone-mode"\u003eRun Mars in Standalone Mode\u003c/h2\u003e\n\u003cp\u003eIn standalone mode, a distributed \u003ccode\u003eMars\u003c/code\u003e job are running standalone on bare hosts without the help of other container orchestration tools.\nBut this requires manual configuration effort and lack other abilities such as automatic failover of workers.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003erun \u003ccode\u003epip install pymars[distributed]\u003c/code\u003e on every node in the cluster to install dependencies needed for distributed execution.\u003c/li\u003e\n\u003cli\u003estart different mars role processes on each node.\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003emars-scheduler -a \u0026lt;scheduler_ip\u0026gt; -p \u0026lt;scheduler_port\u0026gt;\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emars-web -a \u0026lt;web_ip\u0026gt; -p \u0026lt;web_port\u0026gt; -s \u0026lt;scheduler_ip\u0026gt;:\u0026lt;scheduler_port\u0026gt;\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emars-worker -a \u0026lt;worker_ip\u0026gt; -p \u0026lt;worker_port\u0026gt; -s \u0026lt;scheduler_ip\u0026gt;:\u0026lt;scheduler_port\u0026gt;\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eusually there must be at least 1 web-service and 1 scheduler and a certain number of workers.\u003c/li\u003e\n\u003cli\u003eafter all processes started, users can open the python console run snippet to create a session with web-service and submit tasks.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class="language-python"\u003eimport mars.tensor as mt\nimport mars.dataframe as md\nfrom mars.session import new_session\nnew_session(\'http://\u0026lt;web_ip\u0026gt;:\u0026lt;web_port\u0026gt;\').as_default()\na = mt.ones((2000, 2000), chunk_size=200)\nb = mt.inner(a, a)\nb.execute()  # submit tensor to cluster\ndf = md.DataFrame(a).sum()\ndf.execute()  # submit DataFrame to cluster\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:16,href:"https://kubedl.io/docs/recipes/",title:"Recipes",description:"Recipes",content:""},{id:17,href:"https://kubedl.io/docs/help/dingtalk/",title:"Dingtalk",description:"Dingtalk Help.",content:'\u003cp\u003eGet help on joining the Dingtalk(钉钉) Group\u003c/p\u003e\n\u003cfigure\u003e\n  \u003cimg class="img-fluid lazyload blur-up" data-sizes="auto" src="https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_20x0_resize_box_2.png" data-srcset="https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_800x0_resize_box_2.png 800w,https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_700x0_resize_box_2.png 700w,https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_600x0_resize_box_2.png 600w,https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_500x0_resize_box_2.png 500w" width="828" height="1068" alt="Dingtalk"\u003e\n  \u003cnoscript\u003e\u003cimg class="img-fluid" sizes="100vw" srcset="https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_800x0_resize_box_2.png 800w,https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_700x0_resize_box_2.png 700w,https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_600x0_resize_box_2.png 600w,https://kubedl.io/docs/help/dingtalk/kubedl_hu0d572a5a19c12dcb10b88d4fb51252c9_212191_500x0_resize_box_2.png 500w" src="https://kubedl.io/docs/help/dingtalk/kubedl.png" width="828" height="1068" alt="Dingtalk"\u003e\u003c/noscript\u003e\n  \u003cfigcaption class="figure-caption"\u003eDingtalk\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n'},{id:18,href:"https://kubedl.io/docs/recipes/tensorboard/",title:"Tensorboard",description:"",content:'\u003cp\u003eKubeDL can attach a tensorboard to a running tensorflow job.\nUsers can measure and visualize the tensorflow job with the tensorboard.\u003c/p\u003e\n\u003cp\u003eTo use tensorboard, users must ensure that the tensorflow job logs are created and stored in a kubernetes volume(emptyDir hostPath and local are not supported), and the tensorboard can reuse the volume.\u003c/p\u003e\n\u003cp\u003eUsers can set the tensorboard config in the job\u0026rsquo;s annotation with key \u003ccode\u003ekubedl.io/tensorboard-config\u003c/code\u003e as below. After that, users can access the tensorboard through this URL \u003ccode\u003ehttp://\u0026lt;ingress host\u0026gt;/\u0026lt;ingress pathPrefix\u0026gt;/\u0026lt;job namespace\u0026gt;/\u0026lt;job name\u0026gt;\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003e    apiVersion: \u0026quot;kubeflow.org/v1\u0026quot;\n    kind: \u0026quot;TFJob\u0026quot;\n    metadata:\n      name: \u0026quot;mnist\u0026quot;\n      namespace: kubedl \n      annotations:\n +      kubedl.io/tensorboard-config: \'{\u0026quot;logDir\u0026quot;:\u0026quot;/var/log/training\u0026quot;,\u0026quot;ttlSecondsAfterJobFinished\u0026quot;:3600,\u0026quot;ingressSpec\u0026quot;:{\u0026quot;host\u0026quot;:\u0026quot;locahost\u0026quot;,\u0026quot;pathPrefix\u0026quot;:\u0026quot;/tb\u0026quot;}}\'\n    spec:\n      cleanPodPolicy: None \n      tfReplicaSpecs:\n        ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eA full list of supported options are:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-json5"\u003e{\n    \u0026quot;logDir\u0026quot;: \u0026quot;xxx\u0026quot;,            // the path of the tensorflow job logs (required).\n    \u0026quot;ttlSecondsAfterJobFinished\u0026quot;: 3600,     // the TTL to clean up the tensorboard after the job is finished (required).\n    \u0026quot;image\u0026quot;: \u0026quot;xxx\u0026quot;,             // the image of the tensorboard, default value is the job\'s image (optional).\n    \u0026quot;ingressSpec\u0026quot;: {            // the ingress of the tensorboard (required).\n        \u0026quot;host\u0026quot;: \u0026quot;xxx\u0026quot;,          // the ingress host (required).\n        \u0026quot;pathPrefix\u0026quot;: \u0026quot;xxx\u0026quot;,    // the pathPrefix will set to ingress path with the pattern: \u0026lt;pathPrefix\u0026gt;/\u0026lt;job namespace\u0026gt;/\u0026lt;job name\u0026gt; (required).\n        \u0026quot;annotations\u0026quot;: {        // the annotations of the ingress (optional).\n            \u0026quot;xxx\u0026quot;: \u0026quot;xxx\u0026quot;\n        }\n    }\n}\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:19,href:"https://kubedl.io/docs/prologue/quick-start/",title:"Quick Start",description:"Run a simple MNist Tensorflow job with KubeDL.",content:'\u003ch2 id="submit-the-tensorflow-job"\u003eSubmit the TensorFlow job\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/example/tf/tf_job_mnist.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="get-job-status"\u003eGet job status\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl get tfjobs -n kubedl\nkubectl describe tfjob mnist -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="delete-the-job"\u003eDelete the job\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl delete tfjob mnist -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="other-commands"\u003eOther commands\u003c/h2\u003e\n\u003cp\u003e\u003ca href="https://kubedl.io/docs/prologue/commands/"\u003eCommands →\u003c/a\u003e\u003c/p\u003e\n'},{id:20,href:"https://kubedl.io/docs/references/",title:"References",description:"References",content:""},{id:21,href:"https://kubedl.io/docs/contributing/",title:"Contributing",description:"Contributing",content:""},{id:22,href:"https://kubedl.io/docs/workloads/xgboost/",title:"XGBoost",description:"",content:""},{id:23,href:"https://kubedl.io/docs/prologue/commands/",title:"Commands",description:"Commands for jobs",content:'\u003ch3 id="job-kind"\u003eJob kind\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003etfjob\u003c/li\u003e\n\u003cli\u003epytorchjob\u003c/li\u003e\n\u003cli\u003emarsjob\u003c/li\u003e\n\u003cli\u003exgboostjob\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese kinds can be used in the kubectl command.\u003c/p\u003e\n\u003ch3 id="submit"\u003eSubmit\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="kubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/example/tf/tf_job_mnist.yaml"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/example/tf/tf_job_mnist.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="list"\u003eList\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="kubectl get tfjobs -n kubedl"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl get tfjobs -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="get"\u003eGet\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="kubectl describe tfjob mnist -n kubedl"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl describe tfjob mnist -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="delete"\u003eDelete\u003c/h3\u003e\n\u003cdiv class="doks-clipboard"\u003e\n  \u003cbutton class="btn-clipboard btn btn-link" data-clipboard-text="kubectl delete tfjob mnist -n kubedl"\u003e\u003cspan class="copy-status"\u003e\u003c/span\u003e\u003c/button\u003e\n\u003c/div\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl delete tfjob mnist -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:24,href:"https://kubedl.io/docs/help/troubleshooting/",title:"Troubleshooting",description:"Solutions to common problems.",content:'\u003ch2 id="logs"\u003eLogs\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl logs kubedl-controller-manager-0 -n kubedl-system\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="pod-status"\u003ePod status\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl describe pod kubedl-controller-manager-0 -n kubedl-system\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:25,href:"https://kubedl.io/docs/help/",title:"Help",description:"Help KubeDL.",content:""},{id:26,href:"https://kubedl.io/docs/workloads/mpi/",title:"Mpi",description:"",content:""},{id:27,href:"https://kubedl.io/docs/",title:"Docs",description:"Docs Doks.",content:""}];b.add(c),userinput.addEventListener('input',e,!0),suggestions.addEventListener('click',f,!0);function e(){var g=this.value,e=b.search(g,5),f=suggestions.childNodes,h=0,i=e.length,c;for(suggestions.classList.remove('d-none'),e.forEach(function(b){c=document.createElement('div'),c.innerHTML='<a href><span></span><span></span></a>',a=c.querySelector('a'),t=c.querySelector('span:first-child'),d=c.querySelector('span:nth-child(2)'),a.href=b.href,t.textContent=b.title,d.textContent=b.description,suggestions.appendChild(c)});f.length>i;)suggestions.removeChild(f[h])}function f(){while(suggestions.lastChild)suggestions.removeChild(suggestions.lastChild);return!1}})()