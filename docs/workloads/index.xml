<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Workloads on</title><link>https://kubedl.io/docs/workloads/</link><description>Recent content in Workloads on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Tue, 16 Mar 2021 08:43:03 +0100</lastBuildDate><atom:link href="https://kubedl.io/docs/workloads/index.xml" rel="self" type="application/rss+xml"/><item><title>PyTorch</title><link>https://kubedl.io/docs/workloads/pytorch/</link><pubDate>Thu, 01 Apr 2021 16:38:30 -0700</pubDate><guid>https://kubedl.io/docs/workloads/pytorch/</guid><description/></item><item><title>TensorFlow</title><link>https://kubedl.io/docs/workloads/tensorflow/</link><pubDate>Thu, 01 Apr 2021 16:35:14 -0700</pubDate><guid>https://kubedl.io/docs/workloads/tensorflow/</guid><description/></item><item><title>Mars</title><link>https://kubedl.io/docs/workloads/mars/</link><pubDate>Tue, 16 Mar 2021 08:43:34 +0100</pubDate><guid>https://kubedl.io/docs/workloads/mars/</guid><description>What&amp;rsquo;s Mars Mars is a tensor-based unified framework for large-scale data computation which scales Numpy, Pandas and Scikit-learn, see mars-repo for details. As a data computation framework, mars is easy to scale out and can run across hundreds of machines simultaneously to accelerate large scale data tasks.
A distributed mars job includes 3 roles to collaborate with each otherï¼š
WebService: web-service accepts requests from end-users and forwards the whole tensor-graph to scheduler, it provides a dashboard for end users to track job status and submit tasks interactively.</description></item><item><title>XGBoost</title><link>https://kubedl.io/docs/workloads/xgboost/</link><pubDate>Thu, 01 Apr 2021 16:41:11 -0700</pubDate><guid>https://kubedl.io/docs/workloads/xgboost/</guid><description/></item></channel></rss>