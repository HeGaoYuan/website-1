var suggestions=document.getElementById('suggestions'),userinput=document.getElementById('userinput');document.addEventListener('keydown',inputFocus);function inputFocus(a){a.keyCode===191&&(a.preventDefault(),userinput.focus()),a.keyCode===27&&(userinput.blur(),suggestions.classList.add('d-none'))}document.addEventListener('click',function(a){var b=suggestions.contains(a.target);b||suggestions.classList.add('d-none')}),document.addEventListener('keydown',suggestionFocus);function suggestionFocus(b){const d=suggestions.querySelectorAll('a'),e=[...d],a=e.indexOf(document.activeElement);let c=0;b.keyCode===38?(b.preventDefault(),c=a>0?a-1:0,d[c].focus()):b.keyCode===40&&(b.preventDefault(),c=a+1<e.length?a+1:a,d[c].focus())}(function(){var b=new FlexSearch({preset:'score',cache:!0,doc:{id:'id',field:['title','description','content'],store:['href','title','description']}}),c=[{id:0,href:"https://kubedl.io/docs/prologue/introduction/",title:"Introduction",description:"KubeDL runs your deep learning workloads on Kubernetes.",content:'\u003cp\u003eCurrently, KubeDL supports running \u003ca href="https://github.com/tensorflow/tensorflow"\u003eTensorFlow\u003c/a\u003e, \u003ca href="https://github.com/pytorch/pytorch"\u003ePyTorch\u003c/a\u003e,\n\u003ca href="https://github.com/dmlc/xgboost"\u003eXGBoost\u003c/a\u003e, and \u003ca href="https://github.com/mars-project/mars"\u003eMars\u003c/a\u003e distributed training jobs on Kubernetes.\u003c/p\u003e\n\u003ch2 id="key-features"\u003eKey Features\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eSupport different kinds of deep learning training jobs in a single controller. You don\u0026rsquo;t need to run each controller for each job kind.\u003c/li\u003e\n\u003cli\u003eExpose unified \u003ca href="https://kubedl.io/docs/reference-guides/metrics/"\u003eprometheus metrics\u003c/a\u003e for job stats.\u003c/li\u003e\n\u003cli\u003eSave job metadata in a pluggable storage backend such as Mysql to outlive api-server state.\u003c/li\u003e\n\u003cli\u003eRun jobs with custom code \u003ca href="https://kubedl.io/docs/recipes/code-sync/"\u003eon demand\u003c/a\u003e. You no longer need to rebuild the image to include the custom code every time.\u003c/li\u003e\n\u003cli\u003eSupport advanced scheduling features such as gang scheduling.\u003c/li\u003e\n\u003cli\u003e[Work-in-progress] a catchy \u003ca href="#job-dashboard"\u003edashboard\u003c/a\u003e !\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id="get-started"\u003eGet started\u003c/h2\u003e\n\u003cp\u003eThere are two main ways to install KubeDL.\u003c/p\u003e\n\u003ch3 id="install-using-helm"\u003eInstall using Helm\u003c/h3\u003e\n\u003cp\u003eInstall KubeDL using Helm charts. \u003ca href="https://kubedl.io/docs/prologue/install-using-helm/"\u003eGo →\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="install-using-yaml-files"\u003eInstall using YAML files\u003c/h3\u003e\n\u003cp\u003eInstall KubeDL using YAML files. \u003ca href="https://kubedl.io/docs/prologue/quick-start/"\u003eGo →\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="recipes"\u003eRecipes\u003c/h3\u003e\n\u003cp\u003eGet instructions on how to accomplish common tasks with KubeDL. \u003ca href="https://getdoks.org/docs/recipes/project-configuration/"\u003eRecipes →\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="reference-guides"\u003eReference Guides\u003c/h3\u003e\n\u003cp\u003eReferences for apis, metrics etc. \u003ca href="https://kubedl.io/docs/reference-guides/"\u003eReference Guides →\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id="showcase"\u003eShowcase\u003c/h3\u003e\n\u003cp\u003eSee what others have build with KubeDL. \u003ca href="https://getdoks.org/showcase/parietal-numerics-documentation/"\u003eShowcase →\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id="contributing"\u003eContributing\u003c/h2\u003e\n\u003cp\u003eFind out how to contribute to KubeDL. \u003ca href="https://kubedl.io/docs/help/contributing/"\u003eContributing →\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id="help"\u003eHelp\u003c/h2\u003e\n\u003cp\u003eGet help on KubeDL. \u003ca href="https://kubedl.io/docs/help/how-to-update/"\u003eHelp →\u003c/a\u003e\u003c/p\u003e\n'},{id:1,href:"https://kubedl.io/docs/prologue/",title:"Prologue",description:"Prologue Doks.",content:""},{id:2,href:"https://kubedl.io/docs/reference-guides/metrics/",title:"Metrics",description:"",content:"\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eMetric Names\u003c/th\u003e\n\u003cth\u003elabel\u003c/th\u003e\n\u003cth\u003eDescription\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_created\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs created\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_deleted\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs deleted\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_successful\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs successfully finished\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_failed\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs failed\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_restarted\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs restarted\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_running\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs currently running\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_pending\u003c/td\u003e\n\u003ctd\u003ekind\u003c/td\u003e\n\u003ctd\u003eCounts number of jobs currently pending\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_first_pod_launch_delay_seconds\u003c/td\u003e\n\u003ctd\u003ekind, name, namespace, uid\u003c/td\u003e\n\u003ctd\u003eHistogram for recording launch delay duration (from job created to first pod running)\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003ekubedl_jobs_all_pods_launch_delay_seconds\u003c/td\u003e\n\u003ctd\u003ekind, name, namespace, uid\u003c/td\u003e\n\u003ctd\u003eHistogram for recording launch delay duration (from job created to all pods running)\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e\u003ccode\u003elabel\u003c/code\u003e specifics the labels supported for the corresponding prometheus metrics\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003ekind\u003c/code\u003e - the target job kind, e.g. TFJob, PyTorchJob, MarsJob, XGBoostJob\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ename\u003c/code\u003e - the name of the job\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003enamespace\u003c/code\u003e - the namespace of the job\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003euid\u003c/code\u003e - the uid of the job\u003c/li\u003e\n\u003c/ul\u003e\n"},{id:3,href:"https://kubedl.io/docs/recipes/code-sync/",title:"Run custom code on demand",description:"Run custom code on demand",content:'\u003cp\u003eKubeDL supports running jobs with downloading custom code on demand.\nUser can modify the code, reference the code repository and run the jobs without re-building the image every time to include the modified code.\u003c/p\u003e\n\u003cp\u003eCurrently, only support downloading from github. The implementation is pluggable and can easily support other distributed filesystem like HDFS.\u003c/p\u003e\n\u003ch3 id="git-hub"\u003eGit Hub\u003c/h3\u003e\n\u003cp\u003eUsers can set the git config in the job\u0026rsquo;s annotation with key \u003ccode\u003ekubedl.io/git-sync-config\u003c/code\u003e as below. The git repo will be\ndownloaded and saved in the container\u0026rsquo;s \u003ccode\u003eworking dir\u003c/code\u003e by default. Please use the git repo\u0026rsquo;s clone url ending with the \u003ccode\u003e.git\u003c/code\u003e,\nrather than the git repo\u0026rsquo;s web url.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003e    apiVersion: \u0026quot;kubeflow.org/v1\u0026quot;\n    kind: \u0026quot;TFJob\u0026quot;\n    metadata:\n      name: \u0026quot;mnist\u0026quot;\n      namespace: kubedl\n      annotations:\n +      kubedl.io/git-sync-config: \'{\u0026quot;source\u0026quot;: \u0026quot;https://github.com/alibaba/kubedl.git\u0026quot; }\'\n    spec:\n      cleanPodPolicy: None\n      tfReplicaSpecs:\n        ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eA full list of supported options are:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-json5"\u003e\u0026quot;source\u0026quot;: \u0026quot;https://github.com/sample/sample.git\u0026quot;,  // code source (required).\n\u0026quot;image\u0026quot;: \u0026quot;xxx\u0026quot;,     // the image to execute the git-sync logic (optional).\n\u0026quot;rootPath\u0026quot;: \u0026quot;xxx\u0026quot;,  // the path to save downloaded files (optional).\n\u0026quot;destPath\u0026quot;: \u0026quot;xxx\u0026quot;,  // the name of (a symlink to) a directory in which to check-out files (optional).\n\u0026quot;envs\u0026quot;: [],         // user-customized environment variables (optional).\n\u0026quot;branch\u0026quot;: \u0026quot;xxx\u0026quot;,    // git repo branch (optional).\n\u0026quot;revison\u0026quot;: \u0026quot;xxx\u0026quot;,   // git repo commit revision (optional).\n\u0026quot;depth\u0026quot;: \u0026quot;xxx\u0026quot;,     // git sync depth (optional).\n\u0026quot;maxFailures\u0026quot; : 3,  // max consecutive failures allowed (optional).\n\u0026quot;ssh\u0026quot;: false,       // use ssh mode or not (optional).\n\u0026quot;sshFile\u0026quot;: \u0026quot;xxx\u0026quot;,   // ssh file path (optional).\n\u0026quot;user\u0026quot;: \u0026quot;xxx\u0026quot;,      // git config username (optional).\n\u0026quot;password\u0026quot;: \u0026quot;xxx\u0026quot;   // git config password (optional).\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:4,href:"https://kubedl.io/docs/help/contributing/",title:"How to Contribute",description:"You are very welcome to contribute to KubeDL",content:'\u003cp\u003eKubeDL is written in the form of Kubernetes operator and use \u003ca href="https://github.com/kubernetes-sigs/kubebuilder"\u003eKubeBuilder\u003c/a\u003e for code scaffolding.\u003c/p\u003e\n\u003ch3 id="build-the-binary"\u003eBuild the binary\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003emake manager\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="run-the-tests"\u003eRun the tests\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003emake test\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="generate-manifests-crd-rbac-yaml-files-etc"\u003eGenerate manifests: CRD, RBAC YAML files etc\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003emake manifests\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="build-the-docker-image"\u003eBuild the docker image\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003eexport IMG=\u0026lt;your_image_name\u0026gt; \u0026amp;\u0026amp; make docker-build\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="push-the-image"\u003ePush the image\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003edocker push \u0026lt;your_image_name\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCheck the \u003ccode\u003eMakefile\u003c/code\u003e under github root directory for more details\u003c/p\u003e\n\u003cp\u003eTo develop/debug KubeDL controller manager locally, please check the \u003ca href="https://kubedl.io/docs/help/develop-guide/"\u003edebug guide\u003c/a\u003e.\u003c/p\u003e\n'},{id:5,href:"https://kubedl.io/docs/prologue/install-using-helm/",title:"Install Using Helm",description:"Install KubeDL using Helm",content:'\u003ch2 id="install-helm"\u003eInstall Helm\u003c/h2\u003e\n\u003cp\u003eHelm is a package manager for Kubernetes. You can install helm with command below on MacOS\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ebrew install helm\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCheck the \u003ca href="https://helm.sh/docs/intro/install/"\u003ehelm website\u003c/a\u003e for more details.\u003c/p\u003e\n\u003ch2 id="install-kubedl"\u003eInstall KubeDL\u003c/h2\u003e\n\u003cp\u003eFrom the root directory, run\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ehelm install kubedl ./helm/kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can override default values defined in \u003ccode\u003e./helm/kubedl/values.yaml\u003c/code\u003e with \u003ccode\u003e--set\u003c/code\u003e flag, for example:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ehelm install kubedl ./helm/kubedl --set kubedlSysNamespace=kube-system --set resources.requests.cpu=1024m --set resources.requests.memory=2Gi\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHelm will render templates and apply them to cluster and you are good to go :)\u003c/p\u003e\n\u003ch2 id="enable-specific-job-kind"\u003eEnable specific job Kind\u003c/h2\u003e\n\u003cp\u003eKubeDL supports all kinds of jobs(tensorflow, pytorch etc.) in a single Kubernetes operator. You can selectively enable the kind of jobs to support.\nThere are three options:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDefault option. Just install the job CRDs required. KubeDL will automatically enable the corresponding job controller.\u003c/li\u003e\n\u003cli\u003eSet env \u003ccode\u003eWORKLOADS_ENABLE\u003c/code\u003e in KubeDL container. The value is a list of job types to be enabled. For example, \u003ccode\u003eWORKLOADS_ENABLE=TFJob,PytorchJob\u003c/code\u003e means only Tensorflow and Pytorch Job are enabled.\u003c/li\u003e\n\u003cli\u003eSet startup flags \u003ccode\u003e--workloads\u003c/code\u003e in KubeDL container command args. The value is a list of job types to be enabled like \u003ccode\u003e--workloads TFJob,PytorchJob\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n'},{id:6,href:"https://kubedl.io/docs/examples/example/",title:"Mars",description:"Running mars on Kubernetes",content:'\u003ch2 id="whats-mars"\u003eWhat\u0026rsquo;s Mars\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eMars\u003c/code\u003e is a tensor-based unified framework for large-scale data computation which scales Numpy, Pandas and Scikit-learn,\nsee \u003ca href="https://github.com/mars-project/mars"\u003emars-repo\u003c/a\u003e for details. As a data computation framework, \u003ccode\u003emars\u003c/code\u003e is easy to\nscale out and can run across hundreds of machines simultaneously to accelerate large scale data tasks.\u003cbr\u003e\u003c/p\u003e\n\u003cp\u003eA distributed mars job includes 3 roles to collaborate with each other：\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eWebService\u003c/strong\u003e: web-service accepts requests from end-users and forwards the whole tensor-graph to scheduler, it provides a dashboard for end users to track job status and submit tasks interactively.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eScheduler\u003c/strong\u003e: scheduler compiles and holds a global view of tensor-graph, it schedules \u0026lsquo;operands\u0026rsquo; and \u0026lsquo;chunks\u0026rsquo; to workers.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWorker\u003c/strong\u003e:  worker listen to \u0026lsquo;operands\u0026rsquo; and \u0026lsquo;chunks\u0026rsquo; dispatched by scheduler, executes the tasks, and reports results back to scheduler.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id="run-mars-with-kubedl"\u003eRun Mars with KubeDL\u003c/h2\u003e\n\u003cp\u003eRun \u003ccode\u003emars\u003c/code\u003e job on kubernetes natively.\u003c/p\u003e\n\u003ch3 id="1-deploy-kubedl"\u003e1. Deploy KubeDL\u003c/h3\u003e\n\u003cp\u003eFollow the \u003ca href="https://github.com/alibaba/kubedl#getting-started"\u003einstallation tutorial\u003c/a\u003e in README and deploy \u003ccode\u003ekubedl\u003c/code\u003e operator to cluster.\u003c/p\u003e\n\u003ch3 id="2-apply-mars-crd"\u003e2. Apply Mars CRD\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eMars\u003c/code\u003e CRD(CustomResourceDefinition) manifest file describes the structure of a mars job spec. Run the following to apply the CRD:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/crd/bases/kubedl.io_marsjobs.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="3-create-a-mars-job"\u003e3. Create a Mars Job\u003c/h3\u003e\n\u003cp\u003eCreate a YAML spec that describes the requirements of a MarsJob such as the worker, scheduler, WebService like below\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: kubedl.io/v1alpha1\nkind: MarsJob\nmetadata:\n  name: mars-test-demo\n  namespace: default\nspec:\n  cleanPodPolicy: None\n  webHost: mars.domain.com\n  marsReplicaSpecs:\n    Scheduler:\n      replicas: 1\n      restartPolicy: Never\n      template:\n        metadata:\n          labels:\n            mars/service-type: marsscheduler\n        spec:\n          containers:\n            - command:\n                - /bin/sh\n                - -c\n                - python -m mars.deploy.kubernetes.scheduler\n              image: mars-image\n              imagePullPolicy: Always\n              name: mars\n              resources:\n                limits:\n                  cpu: 2\n                  memory: 2Gi\n                requests:\n                  cpu: 2\n                  memory: 2Gi\n          serviceAccountName: kubedl-sa\n    WebService:\n      replicas: 1\n      restartPolicy: Never\n      template:\n        metadata:\n          labels:\n            mars/service-type: marswebservice\n        spec:\n          containers:\n            - command:\n                - /bin/sh\n                - -c\n                - python -m mars.deploy.kubernetes.web\n              image: mars-image\n              imagePullPolicy: Always\n              name: mars\n              resources:\n                limits:\n                  cpu: 2\n                  memory: 2Gi\n                requests:\n                  cpu: 2\n                  memory: 2Gi\n          serviceAccountName: kubedl-sa\n    Worker:\n      replicas: 2\n      restartPolicy: Never\n      template:\n        metadata:\n          labels:\n            mars/service-type: marsworker\n        spec:\n          containers:\n            - command:\n                - /bin/sh\n                - -c\n                - python -m mars.deploy.kubernetes.worker\n              image: mars-image\n              imagePullPolicy: Always\n              name: mars\n              resources:\n                limits:\n                  cpu: 2\n                  memory: 2Gi\n                requests:\n                  cpu: 2\n                  memory: 2Gi\n          serviceAccountName: kubedl-sa\nstatus: {}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe \u003ccode\u003espec\u003c/code\u003e field describes the requirement of each replica, including \u003ccode\u003ereplicas\u003c/code\u003e, \u003ccode\u003erestartPolicy\u003c/code\u003e, \u003ccode\u003etemplate\u003c/code\u003e\u0026hellip;and\nthe \u003ccode\u003estatus\u003c/code\u003e field describes the job current status. Run following command to start an example mars job:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl create -f example/mars/mars-test-demo.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCheck the mars job status:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003e$ kubectl get marsjob\nNAME             STATE     AGE   FINISHED-TTL   MAX-LIFETIME\nmars-test-demo   Running   40m\n$ kubectl get pods\nNAME                                            READY   STATUS             RESTARTS   AGE\nmars-test-demo-scheduler-0                      1/1     Running            0          40m\nmars-test-demo-webservice-0                     1/1     Running            0          40m\nmars-test-demo-worker-0                         1/1     Running            0          40m\nmars-test-demo-worker-1                         1/1     Running            0          40m\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="4-access-web-service"\u003e4. Access web-service.\u003c/h3\u003e\n\u003cdiv align="center"\u003e\n \u003cimg src="../img/mars-ingress.png" width="700" title="Mars-Ingress"\u003e\n\u003c/div\u003e \u003cbr/\u003e\n\u003cp\u003eWeb service visualizes job status, computation process progress and provides an entry for interactive submission.\nHowever, web service instance was running as a pod inside a kubernetes cluster which may not be accessible by external users.\n\u003ccode\u003eKubeDL\u003c/code\u003e provides two access modes for users in different network environment.\u003c/p\u003e\n\u003ch4 id="41-access-web-service-in-cluster"\u003e4.1 Access web-service in-cluster.\u003c/h4\u003e\n\u003cp\u003eFor users in the same network environment with web service instance, they can directly access its \u003cem\u003eservice\u003c/em\u003e without any other additional configurations,\nand the address is formatted as: \u003ccode\u003e{webservice-name}.{namespace}\u003c/code\u003e, it is a \u003ccode\u003eA\u003c/code\u003e record generated by \u003ccode\u003eCoreDNS\u003c/code\u003e, so you have to ensure that \u003ccode\u003eCoreDNS\u003c/code\u003e has been\ndeployed.\u003c/p\u003e\n\u003ch4 id="42-access-web-service-outside-cluster"\u003e4.2 Access web-service outside cluster.\u003c/h4\u003e\n\u003cp\u003eFor users in different network environment(e.g. an internet user wants to access a mars web-service running in vpc),\nusers have to apply an SLB address first, so that they can ping the ip in \u003cstrong\u003evpc\u003c/strong\u003e with a public address by SLB domain resolving, then in job spec, users just need fill the \u003ccode\u003espec.webHost\u003c/code\u003e field with\ntheir applied SLB address, \u003ccode\u003eKubeDL\u003c/code\u003ewill generated ingress instance with routing rules, so that external traffic can be routed to target web service and that\nbecomes available for outside users.\u003c/p\u003e\n\u003ch3 id="5-memory-tuning-policy"\u003e5. Memory Tuning Policy\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003eWorker\u003c/code\u003e is the role that actually performs computing tasks in \u003ccode\u003eMarsJob\u003c/code\u003e.\nMars supports running jobs in different memory usage scenarios. For example, swap cold in-memory data out to spill dirs and persist in kubernetes ephemeral-storage.\n\u003ccode\u003eMars\u003c/code\u003e provides plentiful memory tuning options which has been integrated to \u003ccode\u003eMarsJob\u003c/code\u003e type definition, including :\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eplasmaStore: PlasmaStore specify the socket path of plasma store that handles shared memory between all worker processes.\u003c/li\u003e\n\u003cli\u003elockFreeFileIO: LockFreeFileIO indicates whether spill dirs are dedicated or not.\u003c/li\u003e\n\u003cli\u003espillDirs: SpillDirs specify multiple directory paths, when size of in-memory objects is about to reach the limitation, mars workers will swap cold data out to spill dirs and persist in ephemeral-storage.\u003c/li\u003e\n\u003cli\u003eworkerCachePercentage: WorkerCachePercentage specify the percentage of total available memory size can be used as cache, it will be overridden by workerCacheSize if it is been set.\u003c/li\u003e\n\u003cli\u003eworkerCacheSize：WorkerCacheSize specify the exact cache quantity can be used.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eusers can set above options in \u003ccode\u003ejob.spec.memoryTuningPolicy\u003c/code\u003e field:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003eapiVersion: kubedl.io/v1alpha1\nkind: MarsJob\nmetadata:\n  name: mars-test-demo\n  namespace: default\nspec:\n  cleanPodPolicy: None\n  memoryTuningPolicy:\n    plasmaStore: string              # /etc/pstore/...\n    lockFreeFileIO: bool             # false\n    spillDirs: []string              # ...\n    workerCachePercentage: int32     # 80, indicates 80%\n    workerCacheSize: quantity        # 10Gi\n  marsReplicaSpecs:\n    ...\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="run-mars-in-standalone-mode"\u003eRun Mars in Standalone Mode\u003c/h2\u003e\n\u003cp\u003eIn standalone mode, a distributed \u003ccode\u003eMars\u003c/code\u003e job are running standalone on bare hosts without the help of other container orchestration tools.\nBut this requires manual configuration effort and lack other abilities such as automatic failover of workers.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003erun \u003ccode\u003epip install pymars[distributed]\u003c/code\u003e on every node in the cluster to install dependencies needed for distributed execution.\u003c/li\u003e\n\u003cli\u003estart different mars role processes on each node.\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003emars-scheduler -a \u0026lt;scheduler_ip\u0026gt; -p \u0026lt;scheduler_port\u0026gt;\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emars-web -a \u0026lt;web_ip\u0026gt; -p \u0026lt;web_port\u0026gt; -s \u0026lt;scheduler_ip\u0026gt;:\u0026lt;scheduler_port\u0026gt;\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emars-worker -a \u0026lt;worker_ip\u0026gt; -p \u0026lt;worker_port\u0026gt; -s \u0026lt;scheduler_ip\u0026gt;:\u0026lt;scheduler_port\u0026gt;\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eusually there must be at least 1 web-service and 1 scheduler and a certain number of workers.\u003c/li\u003e\n\u003cli\u003eafter all processes started, users can open the python console run snippet to create a session with web-service and submit tasks.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class="language-python"\u003eimport mars.tensor as mt\nimport mars.dataframe as md\nfrom mars.session import new_session\nnew_session(\'http://\u0026lt;web_ip\u0026gt;:\u0026lt;web_port\u0026gt;\').as_default()\na = mt.ones((2000, 2000), chunk_size=200)\nb = mt.inner(a, a)\nb.execute()  # submit tensor to cluster\ndf = md.DataFrame(a).sum()\ndf.execute()  # submit DataFrame to cluster\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:7,href:"https://kubedl.io/docs/examples/",title:"Examples",description:"Examples",content:""},{id:8,href:"https://kubedl.io/docs/help/develop-guide/",title:"How to Develop",description:"How to develop KubeDL",content:'\u003ch2 id="run-kubedl-in-cluster"\u003eRun KubeDL in Cluster\u003c/h2\u003e\n\u003ch3 id="install-docker"\u003eInstall docker\u003c/h3\u003e\n\u003cp\u003eFollow the \u003ca href="https://docs.docker.com/install/"\u003eofficial docker installation guide\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id="install-minikube"\u003eInstall minikube\u003c/h3\u003e\n\u003cp\u003eFollow the \u003ca href="https://kubernetes.io/docs/tasks/tools/install-minikube/"\u003eofficial minikube installation guide\u003c/a\u003e.\u003c/p\u003e\n\u003ch3 id="customize-kubedl-code"\u003eCustomize KubeDL code\u003c/h3\u003e\n\u003cp\u003eMake your own code changes and validate the build by running \u003ccode\u003emake manager\u003c/code\u003e in KubeDL directory.\u003c/p\u003e\n\u003ch3 id="deploy-customized-operator"\u003eDeploy customized operator\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ePrerequisites: create a \u003ca href="https://hub.docker.com/"\u003edock hub\u003c/a\u003e account ($DOCKERID), and create a \u003ccode\u003ekubedl\u003c/code\u003e repository. Also,\n\u003ca href="https://kubedl.io/docs/prologue/introduction/"\u003einstall KubeDL\u003c/a\u003e;\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 1: \u003ccode\u003edocker login\u003c/code\u003e with the $DOCKERID account;\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 2: \u003ccode\u003eexport IMG=\u0026lt;image_name\u0026gt;\u003c/code\u003e to specify the target image name. e.g., \u003ccode\u003eexport IMG=$DOCKERID/kubedl:test\u003c/code\u003e;\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 3: \u003ccode\u003emake docker-build\u003c/code\u003e to build the image locally;\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 4: \u003ccode\u003emake docker-push\u003c/code\u003e to push the image to dock hub under the \u003ccode\u003ekubedl\u003c/code\u003e repository;\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 5: change the \u003ccode\u003econfig/manager/all_in_one.yaml\u003c/code\u003e and replace the image of the kubedl deployment to \u003ccode\u003e$DOCKERID/kubedl:test\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-yaml"\u003espec:\n      containers:\n        - command:\n            - /manager\n          image: $DOCKERID/kubedl:test\n          imagePullPolicy: Always\n          name: kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 6: \u003ccode\u003ekubectl delete deployment kubedl-controller-manager -n kubedl-system\u003c/code\u003e to remove the old deployment if any;\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003estep 7: \u003ccode\u003ekubectl apply -f config/manager/all_in_one.yaml\u003c/code\u003e to install the new deployment with the customized operator image;\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYou can now perform manual tests and use \u003ccode\u003ekubectl logs kubedl-controller-manager-0 -n kubedl-system\u003c/code\u003e to check controller logs for debugging.\u003c/p\u003e\n\u003ch2 id="run-kubedl-locally"\u003eRun KubeDL locally\u003c/h2\u003e\n\u003ch3 id="set-up-credentials"\u003eSet up credentials\u003c/h3\u003e\n\u003cp\u003eTo run KubeDL locally, you must have the access to the kubernetes cluster, the credential is the\nkube-config cert file.\u003c/p\u003e\n\u003ch3 id="install-crds-and-run-kubedl-operator-locally"\u003eInstall CRDs and run KubeDL operator locally\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003eexport KUBECONFIG=${PATH_TO_CONFIG}\n// or specify the path by --kubeconfig {PATH_TO_CONFIG}\nmake install\nmake run\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eKubeDL supports running workloads selectively. You can enable a specific workload by parsing the\nparameter \u003ccode\u003e--workloads {workload-to-debug}\u003c/code\u003e while starting KubeDL. Check the printed logs to see\nif the job controller is started as expected.\u003c/p\u003e\n'},{id:9,href:"https://kubedl.io/docs/prologue/install-using-yaml/",title:"Install Using Yaml",description:"",content:'\u003ch2 id="install-crds"\u003eInstall CRDs\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/crd/bases/kubeflow.org_pytorchjobs.yaml\nkubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/crd/bases/kubeflow.org_tfjobs.yaml\nkubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/crd/bases/xgboostjob.kubeflow.org_xgboostjobs.yaml\nkubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/crd/bases/kubedl.io_marsjobs.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="install-kubedl-operator"\u003eInstall KubeDL operator\u003c/h2\u003e\n\u003cp\u003eA single yaml file including everything: deployment, rbac etc.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/config/manager/all_in_one.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe official KubeDL operator image is hosted under \u003ca href="https://hub.docker.com/r/kubedl/kubedl"\u003edocker hub\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id="enable-specific-job-kind"\u003eEnable specific job Kind\u003c/h2\u003e\n\u003cp\u003eKubeDL supports all kinds of jobs(tensorflow, pytorch etc.) in a single Kubernetes operator. You can selectively enable the kind of jobs to support.\nThere are three options:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eDefault option. Just install the job CRDs required. KubeDL will automatically enable the corresponding job controller.\u003c/li\u003e\n\u003cli\u003eSet env \u003ccode\u003eWORKLOADS_ENABLE\u003c/code\u003e in KubeDL container. The value is a list of job types to be enabled. For example, \u003ccode\u003eWORKLOADS_ENABLE=TFJob,PytorchJob\u003c/code\u003e means only Tensorflow and Pytorch Job are enabled.\u003c/li\u003e\n\u003cli\u003eSet startup flags \u003ccode\u003e--workloads\u003c/code\u003e in KubeDL container command args. The value is a list of job types to be enabled like \u003ccode\u003e--workloads TFJob,PytorchJob\u003c/code\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n'},{id:10,href:"https://kubedl.io/docs/recipes/",title:"Recipes",description:"Recipes",content:""},{id:11,href:"https://kubedl.io/docs/prologue/quick-start/",title:"Quick Start",description:"One page summary of how to start a new Doks project.",content:'\u003ch2 id="requirements"\u003eRequirements\u003c/h2\u003e\n\u003cp\u003eDoks uses npm to install dependencies and run commands. Installing npm is pretty simple. Download and install \u003ca href="https://nodejs.org/"\u003eNode.js\u003c/a\u003e (it includes npm) for your platform.\u003c/p\u003e\n\u003ch2 id="start-a-new-doks-project"\u003eStart a new Doks project\u003c/h2\u003e\n\u003cp\u003eCreate a new site, change directories, install dependencies, and start development server.\u003c/p\u003e\n\u003ch3 id="create-a-new-site"\u003eCreate a new site\u003c/h3\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003egit clone https://github.com/h-enk/doks.git my-doks-site\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="change-directories"\u003eChange directories\u003c/h3\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003ecd my-doks-site\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="install-dependencies"\u003eInstall dependencies\u003c/h3\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003enpm install\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="start-development-server"\u003eStart development server\u003c/h3\u003e\n\n\u003cpre\u003e\u003ccode class="language-bash"\u003enpm run start\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eDoks will start the Hugo development webserver accessible by default at \u003ccode\u003ehttp://localhost:1313\u003c/code\u003e. Saved changes will live reload in the browser.\u003c/p\u003e\n\u003ch2 id="other-commands"\u003eOther commands\u003c/h2\u003e\n\u003cp\u003eDoks comes with commands for common tasks. \u003ca href="https://kubedl.io/docs/prologue/commands/"\u003eCommands →\u003c/a\u003e\u003c/p\u003e\n'},{id:12,href:"https://kubedl.io/docs/reference-guides/",title:"References Guides",description:"Reference Guides.",content:""},{id:13,href:"https://kubedl.io/docs/prologue/commands/",title:"Commands",description:"Commands for jobs",content:'\u003ch3 id="job-kind"\u003eJob kind\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003etfjob\u003c/li\u003e\n\u003cli\u003epytorchjob\u003c/li\u003e\n\u003cli\u003emarsjob\u003c/li\u003e\n\u003cli\u003exgboostjob\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese kinds can be used in the kubectl command.\u003c/p\u003e\n\u003ch3 id="submit"\u003eSubmit\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl apply -f https://raw.githubusercontent.com/alibaba/kubedl/master/example/tf/tf_job_mnist.yaml\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="list"\u003eList\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl get tfjobs -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="get"\u003eGet\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl describe tfjob mnist -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id="delete"\u003eDelete\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003ekubectl delete tfjob mnist -n kubedl\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:14,href:"https://kubedl.io/docs/help/",title:"Help",description:"Help Doks.",content:""},{id:15,href:"https://kubedl.io/docs/help/how-to-update/",title:"How to Update",description:"Regularly update the installed npm packages to keep your Doks website stable, usable, and secure.",content:'\u003cdiv class="alert alert-warning d-flex" role="alert"\u003e\n  \u003cdiv class="flex-shrink-1 alert-icon"\u003e💡\u003c/div\u003e\n  \u003cdiv class="w-100"\u003eLearn more about \u003ca href="https://docs.npmjs.com/about-semantic-versioning"\u003esemantic versioning\u003c/a\u003e and \u003ca href="https://docs.npmjs.com/cli/v6/using-npm/semver#advanced-range-syntax"\u003eadvanced range syntax\u003c/a\u003e.\u003c/div\u003e\n\u003c/div\u003e\n\u003ch2 id="update-npm-packages"\u003eUpdate npm packages\u003c/h2\u003e\n\u003cp\u003eBump the versions in the \u003ccode\u003edevDependencies\u003c/code\u003e section of \u003ccode\u003e./package.json\u003c/code\u003e to your liking, and run:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003enpm update\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:16,href:"https://kubedl.io/docs/help/troubleshooting/",title:"Troubleshooting",description:"Solutions to common problems.",content:'\u003ch2 id="problems-updating-npm-packages"\u003eProblems updating npm packages\u003c/h2\u003e\n\u003cp\u003eDelete the \u003ccode\u003e./node_modules\u003c/code\u003e folder, and run again:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003enpm install\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id="problems-with-cache"\u003eProblems with cache\u003c/h2\u003e\n\u003cp\u003eDelete the temporary directories:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class="language-bash"\u003enpm run clean\n\u003c/code\u003e\u003c/pre\u003e\n'},{id:17,href:"https://kubedl.io/docs/help/faq/",title:"FAQ",description:"Answers to frequently asked questions.",content:'\u003ch2 id="hyas"\u003eHyas?\u003c/h2\u003e\n\u003cp\u003eDoks is a \u003ca href="https://gethyas.com/themes/doks/"\u003eHyas theme\u003c/a\u003e build by the creator of Hyas.\u003c/p\u003e\n\u003ch2 id="footer-notice"\u003eFooter notice?\u003c/h2\u003e\n\u003cp\u003ePlease keep it in place.\u003c/p\u003e\n\u003ch2 id="keyboard-shortcuts-for-search"\u003eKeyboard shortcuts for search?\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003efocus: \u003ccode\u003e/\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eselect: \u003ccode\u003e↓\u003c/code\u003e and \u003ccode\u003e↑\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eopen: \u003ccode\u003eEnter\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eclose: \u003ccode\u003eEsc\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id="other-documentation"\u003eOther documentation?\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href="https://docs.netlify.com/"\u003eNetlify\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://gohugo.io/documentation/"\u003eHugo\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id="can-i-get-support"\u003eCan I get support?\u003c/h2\u003e\n\u003cp\u003eCreate a topic:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href="https://community.netlify.com/"\u003eNetlify Community\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://discourse.gohugo.io/"\u003eHugo Forums\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id="contact-the-creator"\u003eContact the creator?\u003c/h2\u003e\n\u003cp\u003eSend \u003ccode\u003eh-enk\u003c/code\u003e a message:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href="https://community.netlify.com/"\u003eNetlify Community\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href="https://discourse.gohugo.io/"\u003eHugo Forums\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n'},{id:18,href:"https://kubedl.io/docs/",title:"Docs",description:"Docs Doks.",content:""}];b.add(c),userinput.addEventListener('input',e,!0),suggestions.addEventListener('click',f,!0);function e(){var g=this.value,e=b.search(g,5),f=suggestions.childNodes,h=0,i=e.length,c;for(suggestions.classList.remove('d-none'),e.forEach(function(b){c=document.createElement('div'),c.innerHTML='<a href><span></span><span></span></a>',a=c.querySelector('a'),t=c.querySelector('span:first-child'),d=c.querySelector('span:nth-child(2)'),a.href=b.href,t.textContent=b.title,d.textContent=b.description,suggestions.appendChild(c)});f.length>i;)suggestions.removeChild(f[h])}function f(){while(suggestions.lastChild)suggestions.removeChild(suggestions.lastChild);return!1}})()